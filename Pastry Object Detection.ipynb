{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e683bd5",
   "metadata": {},
   "source": [
    "# <u>Pastry Object Detection</u>\n",
    "\n",
    "**Objective** : The main objective of this notebook is to exhibit the working of SSD-MobileNet trained on Pastry dataset. We'll show 2 methods for object detection here,first we'll do object detection on single Image and then we'll do webcam object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff3610a",
   "metadata": {},
   "source": [
    "### Set required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d41955e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to pre-trained model\n",
    "SAVED_MODEL_PATH = r'C:/Users/dipesh/Desktop/fiverr-hasijayawardana/Pastry Detection/saved_model'\n",
    "\n",
    "# Path to 'label_map.pbtxt' file\n",
    "PATH_TO_LABELS = 'C:/Users/dipesh/Desktop/fiverr-hasijayawardana/Pastry Detection/label_map.pbtxt'\n",
    "\n",
    "# Object detection threshold\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a962a",
   "metadata": {},
   "source": [
    "# 1. Detection on Single Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac08b8b0",
   "metadata": {},
   "source": [
    "### 1.1 Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e31716ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a173b545",
   "metadata": {},
   "source": [
    "### 1.2 Create detection function\n",
    "This function will be responsible to detection objects in the given Image. It'll take the below specified arguments and returns a numpy array of output Image along with list of top 10 detected object with scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2326319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image_path, saved_model_path, labelMap_path, min_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path : Path to input image for the model\n",
    "    saved_model_path : Path to pre-trained model\n",
    "    labelMap_path : Path to 'label_map.pbtxt' file\n",
    "    min_threshold : Minimum decision threshold for classification\n",
    "\n",
    "    Returns : Numpy array of output Image & List of Detected Objects with scores\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------------------------------------\n",
    "\n",
    "    # Object Classes\n",
    "    OBJECT_LABELS = {1: 'Cutlet', 2: 'Egg Patis', 3: 'Fish Bun', 4: 'Fish Roti', 5: 'Kimbula Bun',\n",
    "                     6: 'Puff Pastry', 7: 'Roll', 8: 'Sausage Bun', 9: 'Uludu Wade', 10: 'Vegetable Roti'}\n",
    "\n",
    "    print('Loading model...this will take a minute')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
    "    detect_fn = tf.saved_model.load(saved_model_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Done ! Loading model took {} seconds'.format(round(elapsed_time, 3)))\n",
    "\n",
    "    # -------------------------------------------------------------------------------\n",
    "\n",
    "    # LOAD LABEL MAP DATA FOR PLOTTING\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(labelMap_path,\n",
    "                                                                        use_display_name=True)\n",
    "\n",
    "    # -------------------------------------------------------------------------------\n",
    "\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_with_detections = image.copy()\n",
    "\n",
    "    # -------------------------------------------------------------------------------\n",
    "\n",
    "    detected_objects = {}\n",
    "\n",
    "    # print first 10 objects detected with scores\n",
    "    print(\"\\n----------TOP 10 DETECTED OBJECTS WITH SCORES----------\")\n",
    "    for i in range(11):\n",
    "        obj_class = OBJECT_LABELS.get(detections['detection_classes'][i])\n",
    "        obj_score = detections['detection_scores'][i]\n",
    "        print(obj_class + \" : \" + str(round(obj_score, 3)))\n",
    "\n",
    "        # add data to dictionary\n",
    "        detected_objects[i] = {obj_class: str(round(obj_score, 3))}\n",
    "\n",
    "    print(\"NOTE : Objects with score below threshold are not drawn.\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "    # -------------------------------------------------------------------------------\n",
    "\n",
    "    # SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'],\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=100,\n",
    "        min_score_thresh=min_threshold,\n",
    "        agnostic_mode=False)\n",
    "\n",
    "    image_with_detections = np.array(image_with_detections)\n",
    "\n",
    "    return image_with_detections, detected_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a57fc",
   "metadata": {},
   "source": [
    "### 1.3 Run Inference on Image\n",
    "\n",
    "#### NOTE : The output Image will be display in a window outside the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fb1e3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...this will take a minute\n",
      "Done ! Loading model took 53.592 seconds\n",
      "Running inference for C:/Users/dipesh/Desktop/fiverr-hasijayawardana/train/IMG_0008.JPG... \n",
      "----------TOP 10 DETECTED OBJECTS WITH SCORES----------\n",
      "Sausage Bun : 0.998\n",
      "Sausage Bun : 0.994\n",
      "Roll : 0.983\n",
      "Egg Patis : 0.166\n",
      "Cutlet : 0.159\n",
      "Kimbula Bun : 0.149\n",
      "Kimbula Bun : 0.117\n",
      "Sausage Bun : 0.111\n",
      "Roll : 0.107\n",
      "Roll : 0.106\n",
      "Uludu Wade : 0.089\n",
      "NOTE : Objects with score below threshold are not drawn.\n",
      "-------------------------------------------------------\n",
      "{0: {'Sausage Bun': '0.998'}, 1: {'Sausage Bun': '0.994'}, 2: {'Roll': '0.983'}, 3: {'Egg Patis': '0.166'}, 4: {'Cutlet': '0.159'}, 5: {'Kimbula Bun': '0.149'}, 6: {'Kimbula Bun': '0.117'}, 7: {'Sausage Bun': '0.111'}, 8: {'Roll': '0.107'}, 9: {'Roll': '0.106'}, 10: {'Uludu Wade': '0.089'}}\n"
     ]
    }
   ],
   "source": [
    "# Path to Input Image\n",
    "IMAGE_PATH = 'C:/Users/dipesh/Desktop/fiverr-hasijayawardana/train/IMG_0008.JPG'\n",
    "\n",
    "# Path to save the output Image with name and extension\n",
    "SAVE_PATH = r\"C:/Users/dipesh/Desktop/fiverr-hasijayawardana/outputs/output.jpeg\"\n",
    "\n",
    "# Numpy array of output Image and Dictionary of Top 10 detected objects with scores\n",
    "Output_Image, Detected_Objects = detect_objects(IMAGE_PATH, SAVED_MODEL_PATH, PATH_TO_LABELS, THRESHOLD)\n",
    "\n",
    "print(Detected_Objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b587ba8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the output Image \n",
    "\n",
    "cv2.imshow(\"OUTPUT\", Output_Image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049b1863",
   "metadata": {},
   "source": [
    "# 2. Webcam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d84cc",
   "metadata": {},
   "source": [
    "### 2.1 Create function to process webcam frames\n",
    "\n",
    "This is a pure function which take an 416x416 Image frame as Input and return an output Image with bounding boxes drawn for objects above set threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "482216e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(image, detect_function, labelMap_path, min_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : Numpy array Image frame\n",
    "    detect_function : Loaded model detection function\n",
    "    labelMap_path : Path to 'label_map.pbtxt' file\n",
    "    min_threshold : Minimum decision threshold for classification\n",
    "\n",
    "    Returns : Numpy array of output Image\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------------------------------------\n",
    "\n",
    "    # LOAD LABEL MAP DATA FOR PLOTTING\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(labelMap_path,\n",
    "                                                                        use_display_name=True)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_function(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    # -------------------------------------------------------------------------------\n",
    "\n",
    "    # SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'],\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=100,\n",
    "        min_score_thresh=min_threshold,\n",
    "        agnostic_mode=False)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c6c98",
   "metadata": {},
   "source": [
    "### 2.2 Create function for Webcam Detection\n",
    "This function is for the webcam object detection. When you execute this function,It'll automatically activate the webcam and start detecting objects frame by frame. The current speed is 3FPS,but can be further increased by running on GPU/TPU and reducing preprocessing/postprocessing of the Images.\n",
    "\n",
    "**NOTE** : If you are using a webcam try changing \"cv2.VideoCapture(0)\" with \"cv2.VideoCapture(1)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35977aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_webcam(detection_function, labelMap_path, min_threshold=0.5):\n",
    "\n",
    "    print(\"Starting webcam...\")\n",
    "\n",
    "    # define a video capture object\n",
    "    vid = cv2.VideoCapture(0)\n",
    "\n",
    "    while (True):\n",
    "\n",
    "        # Capture the video frame by frame\n",
    "        ret, frame = vid.read()\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "\n",
    "        image = cv2.resize(frame, (416, 416))\n",
    "\n",
    "        # # Numpy array of output Image and Dictionary of Top 10 detected objects with scores\n",
    "        Output_Image = process_frame(image, detection_function, labelMap_path, min_threshold)\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "\n",
    "        # resizing the output image\n",
    "        frame = cv2.resize(Output_Image, (620, 620))\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # the 'q' button is set as the\n",
    "        # quitting button you may use any\n",
    "        # desired button of your choice\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # After the loop release the cap object\n",
    "    vid.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf76e28",
   "metadata": {},
   "source": [
    "### 2.3 Start Webcam !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a202438e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...this will take a minute\n",
      "Starting webcam...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
    "print(\"Loading model...this will take a minute\")\n",
    "detect_fn = tf.saved_model.load(SAVED_MODEL_PATH)\n",
    "\n",
    "detect_webcam(detect_fn, PATH_TO_LABELS, THRESHOLD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
